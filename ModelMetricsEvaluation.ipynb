{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Assuming your results are stored in 'balancedDataOutcomes.csv'\n",
        "results_df = pd.read_csv(\"DataOutcomes.csv\")\n",
        "\n",
        "# Drop unwanted columns\n",
        "results_df = results_df.drop(columns=[\"Training Time (s)\", \"Prediction Time (s)\", \"Fold\"])\n",
        "\n",
        "# Group by classifier and training set type, then calculate average metrics\n",
        "# Changed from tuple to list for column selection\n",
        "grouped_results = results_df.groupby([\"Classifier Name\", \"Balanced or Unbalanced Train Set\"])[\n",
        "    [\"Accuracy\", \"Precision\", \"Recall\", \"F1 Score\", \"ROC AUC\"] # Use a list here\n",
        "].mean()\n",
        "\n",
        "# Sort the grouped results by the specified metric priority\n",
        "grouped_results = grouped_results.sort_values(\n",
        "    by=[\"Recall\", \"F1 Score\", \"ROC AUC\", \"Precision\", \"Accuracy\"],\n",
        "    ascending=[False, False, False, False, False]  # Sort in descending order for all metrics\n",
        ")\n",
        "\n",
        "\n",
        "# Print the grouped results\n",
        "print(grouped_results)\n",
        "\n",
        "# Export to CSV\n",
        "\n",
        "# Convert MultiIndex to columns\n",
        "grouped_results = grouped_results.reset_index()  # This keeps the model names and training set types\n",
        "\n",
        "\n",
        "grouped_results[\"Accuracy\"] = grouped_results[\"Accuracy\"].map(\"{:.4f}\".format)  # Example with 4 decimal places\n",
        "grouped_results[\"Precision\"] = grouped_results[\"Precision\"].map(\"{:.4f}\".format)  # Example with 4 decimal places\n",
        "grouped_results[\"Recall\"] = grouped_results[\"Recall\"].map(\"{:.4f}\".format)  # Example with 4 decimal places\n",
        "grouped_results[\"F1 Score\"] = grouped_results[\"F1 Score\"].map(\"{:.4f}\".format)  # Example with 4 decimal places\n",
        "grouped_results[\"ROC AUC\"] = grouped_results[\"ROC AUC\"].map(\"{:.4f}\".format)  # Example with 4 decimal places\n",
        "\n",
        "\n",
        "grouped_results.to_csv(\"sorted_classifier_results.csv\", encoding='utf-8', index=False)  # Also, explicitly set index=False\n",
        "print(\"Sorted results exported to sorted_classifier_results.csv\")\n",
        "\n",
        "# Check for overfitting/underfitting\n",
        "for classifier_name in results_df[\"Classifier Name\"].unique():\n",
        "    for balanced_type in results_df[\"Balanced or Unbalanced Train Set\"].unique():\n",
        "        train_accuracy = results_df[\n",
        "            (results_df[\"Classifier Name\"] == classifier_name) &\n",
        "            (results_df[\"Balanced or Unbalanced Train Set\"] == balanced_type) &\n",
        "            (results_df[\"Training or Test Set\"] == \"Train\")\n",
        "        ][\"Accuracy\"].mean()\n",
        "\n",
        "        test_accuracy = results_df[\n",
        "            (results_df[\"Classifier Name\"] == classifier_name) &\n",
        "            (results_df[\"Balanced or Unbalanced Train Set\"] == balanced_type) &\n",
        "            (results_df[\"Training or Test Set\"] == \"Test\")\n",
        "        ][\"Accuracy\"].mean()\n",
        "\n",
        "        print(f\"{classifier_name} ({balanced_type}):\")\n",
        "        print(f\"  Train Accuracy: {train_accuracy:.2f}\")\n",
        "        print(f\"  Test Accuracy: {test_accuracy:.2f}\")\n",
        "\n",
        "        if train_accuracy > test_accuracy + 0.1:  # Arbitrary threshold for overfitting\n",
        "            print(\"  Potential Overfitting Detected\")\n",
        "        elif test_accuracy < 0.7:  # Arbitrary threshold for underfitting\n",
        "            print(\"  Potential Underfitting Detected\")\n",
        "        else:\n",
        "            print(\"  Model performance is acceptable\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mvYZzaJ4h5hU",
        "outputId": "7a1cf7d8-cd61-4f0c-c650-560751c9cad9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                      Accuracy  Precision  \\\n",
            "Classifier Name     Balanced or Unbalanced Train Set                        \n",
            "XGBoost             Balanced                           1.00000    0.75375   \n",
            "Logistic Regression Balanced                           0.96250    0.51625   \n",
            "Adaboost            Balanced                           0.95375    0.50500   \n",
            "Neural Network      Balanced                           1.00000    0.78250   \n",
            "Gradient Boosting   Balanced                           0.96250    0.53875   \n",
            "XGBoost             Unbalanced                         1.00000    0.97375   \n",
            "Decision Tree       Balanced                           0.94875    0.52875   \n",
            "Random Forest       Balanced                           0.96375    0.60000   \n",
            "Naive Bayes         Balanced                           0.94500    0.51500   \n",
            "                    Unbalanced                         0.98000    0.06125   \n",
            "Neural Network      Unbalanced                         1.00000    0.94000   \n",
            "Gradient Boosting   Unbalanced                         1.00000    0.84125   \n",
            "Decision Tree       Unbalanced                         1.00000    0.84875   \n",
            "Adaboost            Unbalanced                         1.00000    0.77000   \n",
            "Logistic Regression Unbalanced                         1.00000    0.88125   \n",
            "Random Forest       Unbalanced                         1.00000    0.87000   \n",
            "\n",
            "                                                       Recall  F1 Score  \\\n",
            "Classifier Name     Balanced or Unbalanced Train Set                      \n",
            "XGBoost             Balanced                          0.92250   0.81625   \n",
            "Logistic Regression Balanced                          0.91625   0.52750   \n",
            "Adaboost            Balanced                          0.90875   0.51375   \n",
            "Neural Network      Balanced                          0.90375   0.83125   \n",
            "Gradient Boosting   Balanced                          0.89375   0.55375   \n",
            "XGBoost             Unbalanced                        0.89250   0.93125   \n",
            "Decision Tree       Balanced                          0.88500   0.54000   \n",
            "Random Forest       Balanced                          0.87000   0.62750   \n",
            "Naive Bayes         Balanced                          0.85750   0.50875   \n",
            "                    Unbalanced                        0.82875   0.11375   \n",
            "Neural Network      Unbalanced                        0.81000   0.87125   \n",
            "Gradient Boosting   Unbalanced                        0.74750   0.78875   \n",
            "Decision Tree       Unbalanced                        0.72875   0.78250   \n",
            "Adaboost            Unbalanced                        0.68875   0.72750   \n",
            "Logistic Regression Unbalanced                        0.63000   0.73625   \n",
            "Random Forest       Unbalanced                        0.61875   0.72375   \n",
            "\n",
            "                                                      ROC AUC  \n",
            "Classifier Name     Balanced or Unbalanced Train Set           \n",
            "XGBoost             Balanced                          0.99000  \n",
            "Logistic Regression Balanced                          0.98375  \n",
            "Adaboost            Balanced                          0.98250  \n",
            "Neural Network      Balanced                          0.97750  \n",
            "Gradient Boosting   Balanced                          0.98250  \n",
            "XGBoost             Unbalanced                        0.98875  \n",
            "Decision Tree       Balanced                          0.96500  \n",
            "Random Forest       Balanced                          0.97750  \n",
            "Naive Bayes         Balanced                          0.95500  \n",
            "                    Unbalanced                        0.96000  \n",
            "Neural Network      Unbalanced                        0.98500  \n",
            "Gradient Boosting   Unbalanced                        0.89000  \n",
            "Decision Tree       Unbalanced                        0.91375  \n",
            "Adaboost            Unbalanced                        0.98125  \n",
            "Logistic Regression Unbalanced                        0.97500  \n",
            "Random Forest       Unbalanced                        0.96125  \n",
            "Sorted results exported to sorted_classifier_results.csv\n",
            "Logistic Regression (Unbalanced):\n",
            "  Train Accuracy: 1.00\n",
            "  Test Accuracy: 1.00\n",
            "  Model performance is acceptable\n",
            "Logistic Regression (Balanced):\n",
            "  Train Accuracy: 0.95\n",
            "  Test Accuracy: 0.97\n",
            "  Model performance is acceptable\n",
            "Decision Tree (Unbalanced):\n",
            "  Train Accuracy: 1.00\n",
            "  Test Accuracy: 1.00\n",
            "  Model performance is acceptable\n",
            "Decision Tree (Balanced):\n",
            "  Train Accuracy: 0.93\n",
            "  Test Accuracy: 0.96\n",
            "  Model performance is acceptable\n",
            "Naive Bayes (Unbalanced):\n",
            "  Train Accuracy: 0.98\n",
            "  Test Accuracy: 0.98\n",
            "  Model performance is acceptable\n",
            "Naive Bayes (Balanced):\n",
            "  Train Accuracy: 0.92\n",
            "  Test Accuracy: 0.97\n",
            "  Model performance is acceptable\n",
            "XGBoost (Unbalanced):\n",
            "  Train Accuracy: 1.00\n",
            "  Test Accuracy: 1.00\n",
            "  Model performance is acceptable\n",
            "XGBoost (Balanced):\n",
            "  Train Accuracy: 1.00\n",
            "  Test Accuracy: 1.00\n",
            "  Model performance is acceptable\n",
            "Random Forest (Unbalanced):\n",
            "  Train Accuracy: 1.00\n",
            "  Test Accuracy: 1.00\n",
            "  Model performance is acceptable\n",
            "Random Forest (Balanced):\n",
            "  Train Accuracy: 0.94\n",
            "  Test Accuracy: 0.99\n",
            "  Model performance is acceptable\n",
            "Adaboost (Unbalanced):\n",
            "  Train Accuracy: 1.00\n",
            "  Test Accuracy: 1.00\n",
            "  Model performance is acceptable\n",
            "Adaboost (Balanced):\n",
            "  Train Accuracy: 0.94\n",
            "  Test Accuracy: 0.96\n",
            "  Model performance is acceptable\n",
            "Neural Network (Unbalanced):\n",
            "  Train Accuracy: 1.00\n",
            "  Test Accuracy: 1.00\n",
            "  Model performance is acceptable\n",
            "Neural Network (Balanced):\n",
            "  Train Accuracy: 1.00\n",
            "  Test Accuracy: 1.00\n",
            "  Model performance is acceptable\n",
            "Gradient Boosting (Unbalanced):\n",
            "  Train Accuracy: 1.00\n",
            "  Test Accuracy: 1.00\n",
            "  Model performance is acceptable\n",
            "Gradient Boosting (Balanced):\n",
            "  Train Accuracy: 0.94\n",
            "  Test Accuracy: 0.98\n",
            "  Model performance is acceptable\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Assuming grouped_results is already calculated as per your provided code\n",
        "\n",
        "# Define metrics and classifier names\n",
        "metrics = [\"Accuracy\", \"Precision\", \"Recall\", \"F1 Score\", \"ROC AUC\"]\n",
        "classifier_names = grouped_results[\"Classifier Name\"].unique()\n",
        "\n",
        "# Create a bar chart for each metric and dataset type\n",
        "for metric in metrics:\n",
        "    for dataset_type in [\"Balanced\", \"Unbalanced\"]:\n",
        "        # Filter data for the current metric and dataset type\n",
        "        data = grouped_results[grouped_results[\"Balanced or Unbalanced Train Set\"] == dataset_type]\n",
        "\n",
        "        # Create the bar chart\n",
        "        plt.figure(figsize=(10, 6))  # Adjust figure size as needed\n",
        "        plt.bar(classifier_names, data[metric].astype(float))\n",
        "        plt.xlabel(\"Classifier\")\n",
        "        plt.ylabel(metric)\n",
        "        plt.title(f\"{metric} - {dataset_type} Dataset\")\n",
        "        plt.xticks(rotation=45, ha=\"right\")  # Rotate x-axis labels\n",
        "        plt.tight_layout()\n",
        "\n",
        "        # Export the current bar chart\n",
        "        plt.savefig(f\"{metric}_{dataset_type}.png\")  # Change file format if needed\n",
        "        plt.close()  # Close the figure to avoid overlapping plots\n",
        "\n",
        "print(\"Bar charts exported successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RYcT8ucrtBeP",
        "outputId": "0e13aa7b-24d8-4d27-c586-8a866e7a91e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bar charts exported successfully!\n"
          ]
        }
      ]
    }
  ]
}